{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e76cac92",
   "metadata": {},
   "source": [
    "# Handwritten Number Recognization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07001100",
   "metadata": {},
   "source": [
    "## Group Information\n",
    "Team Name:\n",
    "<br>Participants:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e102a36b",
   "metadata": {},
   "source": [
    "## 0. Project Information\n",
    "We have already creat the training dataset in *CreateTrainSet* . In this module, we will used the training dataset to recognize the handwritten digits.  \n",
    "We are going to complete the following steps:\n",
    "* Import the image with handwritten digits or take a photo of the handwritten digits to be detected.\n",
    "* Preprocess the image, including but not limited to converting the picture into a grayscale image, and then into a binary image; segmenting the picture to extract a single digit.\n",
    "* Recognize the handwritten digits based on kNN algorithm with the functions supplied by OpenCV.\n",
    "* Display the detected digits with digital tube."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89fc161",
   "metadata": {},
   "source": [
    "## 1. Initialize the Environment\n",
    "As usual, let's first initialize the environment. This step includes importing modules, geting project and file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "620478b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "# number detected related\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from lib import imshow\n",
    "import random\n",
    "\n",
    "# get the project path\n",
    "PRJ_PATH = os.getcwd()\n",
    "# OPENCV_data.npz\n",
    "TRAIN_DATA_NAME = \"OPENCV_data.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69863d",
   "metadata": {},
   "source": [
    "We will complete some independent functions in *my_function*.   \n",
    "Here let's first import the function we are going to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34544603",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport my_function\n",
    "from my_function import image_split_row, image_split_column, led_display, take_photo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b016c",
   "metadata": {},
   "source": [
    "## 2. Import the Training Dataset\n",
    "In this module let's first import the training dataset which we generate in *CreateTrainSet* . Then let's create a kNN object and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "880555cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the knn training data\n",
    "with np.load(PRJ_PATH + '/TrainingData/' + TRAIN_DATA_NAME) as data:\n",
    "    train = data[\"train\"]\n",
    "    train_labels = data[\"train_labels\"]\n",
    "train = train.astype(np.float32)\n",
    "train_labels = train_labels.astype(np.float32)\n",
    "\n",
    "# create KNN obj\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train,cv2.ml.ROW_SAMPLE,train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3257e765",
   "metadata": {},
   "source": [
    "## 3. Image Preprocessing\n",
    "Before we start digits recognition, we need to do some preprocessing on the image. The preprocess includes the change of the image color gamut and the space domain. Let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a691d4c",
   "metadata": {},
   "source": [
    "### Import Pending Pictures\n",
    "- In first stage, we will use existing pictures with handwritten digits. Import the image with `dst = cv2.imread(filename)` and show the image with `imshow(src)`.  \n",
    "<br>\n",
    "- In late stage, we will use the camera to take pictures. In this stage, you first need to build the camera control circuit on the breadboard. Then finish the function of taking pictures in `take_photo()` of *my_function*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf5e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera activated\n"
     ]
    }
   ],
   "source": [
    "image = take_photo()\n",
    "img = cv2.imread(image)\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d7b6ce",
   "metadata": {},
   "source": [
    "### Get the Grayscale Image\n",
    "After we get the image, we should first convert the color image into a grayscale image.\n",
    "<br>\n",
    "Do it with `dst = cv2.cvtColor(src,code)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac745b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "imshow(imgGray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e1487",
   "metadata": {},
   "source": [
    "### Get the Binary Image\n",
    "After getting the grayscale image, we need to further convert the grayscale image into a binary image.\n",
    "<br>\n",
    "Do it with `dst=cv2.threshold(src, thresh, maxval, type)`.\n",
    "<br>\n",
    "**Note**: try to adjust parameter `thresh` to get a binary image without extra points or noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277e8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "_threshold, imgBin = cv2.threshold(imgGray,71,255,cv2.THRESH_BINARY_INV)\n",
    "imshow(imgBin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ecc65f",
   "metadata": {},
   "source": [
    "### Split the Image\n",
    "\n",
    "When we start to recognize handwritten digits, we should find out the corresponding digits one by one. So we need to segment the binary image to obtain a single digit.\n",
    "\n",
    "Remeber how we split the image in *CreatTrainSet*? Since the numbers in *digits.png* have the same size (20x20) and are arranged neatly, we can simply divide *digits.png*  according to the size of the numbers. \n",
    "But this time, the numbers to be detected are not restricted to strict positions, and their size may also be different, which means we can no longer use `np.hsplit()` and `np.vsplit()` for segmentation.\n",
    "\n",
    "However in the previous steps, we have already get the binary image which only contains 0 and 255. In our project, 0 represents black, which is the background of the image. And 255 represents white, which constitutes the number on the picture. Therefor, we can determine the boundary of the handwritten number through the transformation of 0 and 255.\n",
    "\n",
    "Head to [my_function.py](/edit/ProjectExercise/my_function.py) to complete function `image_split_row` and `image_split_column`. \n",
    "\n",
    "- In the first stage, we will use the picture with only one line of numbers. Just run the following cell to view the split image.\n",
    "- In the later stage, we will use the picture with multiple lines of numbers. Adjust the code in the cell below, and then run it to see the splitted image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8035b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgCol = image_split_column(imgBin)\n",
    "imgMonos = []\n",
    "for col in range(0,len(imgCol)):\n",
    "    imgMono = image_split_row(imgCol[col])\n",
    "    print(f\"{(col)}:\")\n",
    "    imshow(imgMono[0])\n",
    "    imgMonos.append(imgMono[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843c30e1",
   "metadata": {},
   "source": [
    "Here comes another problem: these images have different size.\n",
    "We need to resize them to a uniform shape. \n",
    "Also we should reshape the image to make it consistent with the kNN lib. \n",
    "Fill in the two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e06c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "resizeSize = (20,20)\n",
    "reShapeSize = (1,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c089391c",
   "metadata": {},
   "source": [
    "## 4. Recognize the Handwritten Number\n",
    "Let's complete the resize and reshape operations of the image, and do the recognization.\n",
    "- In the first stage, we only have one line of numbers. Run the following cell to get the recognized numbers.\n",
    "- In the later stage, we will deal with multipul lines of numbers. Adjust the cell below to display the multiple rows of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbace1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize and reshape the image with single number\n",
    "# then recognize the number with knn.findNearest(imgReshape,k=?)\n",
    "numberList = []\n",
    "for i in range(0,len(imgMonos)):\n",
    "    imgResize = cv2.resize(imgMonos[i], resizeSize)\n",
    "    imshow(imgResize)\n",
    "    imgReshape = imgResize.reshape(reShapeSize).astype(np.float32)\n",
    "    _,result,_,_ = knn.findNearest(imgReshape,k=1)\n",
    "    numberList.append(int(result))\n",
    "print(\"The \"+str(1)+\"th row has:\" + str(numberList))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ca3ac",
   "metadata": {},
   "source": [
    "## 5. Display the Number by Digital Tube\n",
    "Next we will use a digital tube to display the numbers we finally recognize.\n",
    "\n",
    "We will use a common anode digital tube to display the result. Please complete the following operations:\n",
    "1. Use breadboard, DuPont cables and GPIO pins of Raspberry Pi to complete the circuit for digital tube.\n",
    "2. Complete the relevant code for digital tube in function `led_display` of *my_function.py*.\n",
    "\n",
    "About the cell below:\n",
    "- In the first stage with only one line of numbers,run the cell below to display the result.\n",
    "- In the later stage with multiple lines of numbers, adjust the code in the cell to display the total results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18075b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the image splite and reshape\n",
    "# then recognize the number with knn.findNearest(imgReshape,k=?)\n",
    "\n",
    "led_display(numberList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbe9197",
   "metadata": {},
   "source": [
    "# Congratulate!\n",
    "## You have completed all the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da7523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9268c22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20057a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105eff67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
